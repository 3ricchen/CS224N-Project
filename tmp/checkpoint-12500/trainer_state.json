{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.4416805059891877,
  "eval_steps": 500,
  "global_step": 12500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0035334440479135015,
      "grad_norm": 11.242419242858887,
      "learning_rate": 1e-05,
      "loss": 6.9178,
      "step": 100
    },
    {
      "epoch": 0.007066888095827003,
      "grad_norm": 8.21684741973877,
      "learning_rate": 2e-05,
      "loss": 5.2158,
      "step": 200
    },
    {
      "epoch": 0.010600332143740504,
      "grad_norm": 18.501537322998047,
      "learning_rate": 3e-05,
      "loss": 2.2816,
      "step": 300
    },
    {
      "epoch": 0.014133776191654006,
      "grad_norm": 13.512194633483887,
      "learning_rate": 4e-05,
      "loss": 0.4146,
      "step": 400
    },
    {
      "epoch": 0.017667220239567506,
      "grad_norm": 7.186823844909668,
      "learning_rate": 5e-05,
      "loss": 0.3584,
      "step": 500
    },
    {
      "epoch": 0.02120066428748101,
      "grad_norm": 3.991400718688965,
      "learning_rate": 4.98201503543038e-05,
      "loss": 0.3586,
      "step": 600
    },
    {
      "epoch": 0.02473410833539451,
      "grad_norm": 5.979557037353516,
      "learning_rate": 4.9640300708607604e-05,
      "loss": 0.3381,
      "step": 700
    },
    {
      "epoch": 0.02826755238330801,
      "grad_norm": 3.350285291671753,
      "learning_rate": 4.9460451062911405e-05,
      "loss": 0.345,
      "step": 800
    },
    {
      "epoch": 0.031800996431221515,
      "grad_norm": 6.983935832977295,
      "learning_rate": 4.928060141721521e-05,
      "loss": 0.3384,
      "step": 900
    },
    {
      "epoch": 0.03533444047913501,
      "grad_norm": 5.302139759063721,
      "learning_rate": 4.910075177151901e-05,
      "loss": 0.3293,
      "step": 1000
    },
    {
      "epoch": 0.038867884527048514,
      "grad_norm": 13.931511878967285,
      "learning_rate": 4.8920902125822814e-05,
      "loss": 0.3373,
      "step": 1100
    },
    {
      "epoch": 0.04240132857496202,
      "grad_norm": 2.848280191421509,
      "learning_rate": 4.8741052480126615e-05,
      "loss": 0.3302,
      "step": 1200
    },
    {
      "epoch": 0.045934772622875514,
      "grad_norm": 4.866534233093262,
      "learning_rate": 4.856120283443042e-05,
      "loss": 0.3267,
      "step": 1300
    },
    {
      "epoch": 0.04946821667078902,
      "grad_norm": 3.659559488296509,
      "learning_rate": 4.8381353188734216e-05,
      "loss": 0.3226,
      "step": 1400
    },
    {
      "epoch": 0.05300166071870252,
      "grad_norm": 3.1809144020080566,
      "learning_rate": 4.8201503543038024e-05,
      "loss": 0.3252,
      "step": 1500
    },
    {
      "epoch": 0.05653510476661602,
      "grad_norm": 5.5572028160095215,
      "learning_rate": 4.8021653897341825e-05,
      "loss": 0.3148,
      "step": 1600
    },
    {
      "epoch": 0.06006854881452952,
      "grad_norm": 26.186689376831055,
      "learning_rate": 4.7841804251645626e-05,
      "loss": 0.3178,
      "step": 1700
    },
    {
      "epoch": 0.06360199286244303,
      "grad_norm": 16.540754318237305,
      "learning_rate": 4.7661954605949426e-05,
      "loss": 0.3199,
      "step": 1800
    },
    {
      "epoch": 0.06713543691035652,
      "grad_norm": 3.7190308570861816,
      "learning_rate": 4.7482104960253234e-05,
      "loss": 0.3198,
      "step": 1900
    },
    {
      "epoch": 0.07066888095827002,
      "grad_norm": 19.312763214111328,
      "learning_rate": 4.730225531455703e-05,
      "loss": 0.3208,
      "step": 2000
    },
    {
      "epoch": 0.07420232500618353,
      "grad_norm": 8.05016040802002,
      "learning_rate": 4.7122405668860836e-05,
      "loss": 0.3302,
      "step": 2100
    },
    {
      "epoch": 0.07773576905409703,
      "grad_norm": 9.219091415405273,
      "learning_rate": 4.6942556023164636e-05,
      "loss": 0.3152,
      "step": 2200
    },
    {
      "epoch": 0.08126921310201053,
      "grad_norm": 3.501424789428711,
      "learning_rate": 4.676270637746844e-05,
      "loss": 0.3097,
      "step": 2300
    },
    {
      "epoch": 0.08480265714992404,
      "grad_norm": 11.660674095153809,
      "learning_rate": 4.658285673177224e-05,
      "loss": 0.3059,
      "step": 2400
    },
    {
      "epoch": 0.08833610119783754,
      "grad_norm": 3.1868367195129395,
      "learning_rate": 4.6403007086076046e-05,
      "loss": 0.294,
      "step": 2500
    },
    {
      "epoch": 0.09186954524575103,
      "grad_norm": 7.198179244995117,
      "learning_rate": 4.6223157440379846e-05,
      "loss": 0.3135,
      "step": 2600
    },
    {
      "epoch": 0.09540298929366453,
      "grad_norm": 8.992080688476562,
      "learning_rate": 4.604330779468365e-05,
      "loss": 0.3057,
      "step": 2700
    },
    {
      "epoch": 0.09893643334157803,
      "grad_norm": 2.399609088897705,
      "learning_rate": 4.586345814898745e-05,
      "loss": 0.2937,
      "step": 2800
    },
    {
      "epoch": 0.10246987738949154,
      "grad_norm": 9.025713920593262,
      "learning_rate": 4.5683608503291256e-05,
      "loss": 0.2829,
      "step": 2900
    },
    {
      "epoch": 0.10600332143740504,
      "grad_norm": 5.894839763641357,
      "learning_rate": 4.550375885759505e-05,
      "loss": 0.3057,
      "step": 3000
    },
    {
      "epoch": 0.10953676548531854,
      "grad_norm": 11.53746223449707,
      "learning_rate": 4.532390921189886e-05,
      "loss": 0.2921,
      "step": 3100
    },
    {
      "epoch": 0.11307020953323205,
      "grad_norm": 5.6951799392700195,
      "learning_rate": 4.514405956620266e-05,
      "loss": 0.2974,
      "step": 3200
    },
    {
      "epoch": 0.11660365358114554,
      "grad_norm": 9.74968147277832,
      "learning_rate": 4.496420992050646e-05,
      "loss": 0.2876,
      "step": 3300
    },
    {
      "epoch": 0.12013709762905904,
      "grad_norm": 4.059431552886963,
      "learning_rate": 4.478436027481026e-05,
      "loss": 0.2954,
      "step": 3400
    },
    {
      "epoch": 0.12367054167697254,
      "grad_norm": 11.388775825500488,
      "learning_rate": 4.460451062911406e-05,
      "loss": 0.2898,
      "step": 3500
    },
    {
      "epoch": 0.12720398572488606,
      "grad_norm": 9.650588035583496,
      "learning_rate": 4.442466098341787e-05,
      "loss": 0.2772,
      "step": 3600
    },
    {
      "epoch": 0.13073742977279953,
      "grad_norm": 5.235257625579834,
      "learning_rate": 4.424481133772166e-05,
      "loss": 0.2745,
      "step": 3700
    },
    {
      "epoch": 0.13427087382071304,
      "grad_norm": 7.478841781616211,
      "learning_rate": 4.406496169202547e-05,
      "loss": 0.2842,
      "step": 3800
    },
    {
      "epoch": 0.13780431786862654,
      "grad_norm": 11.058333396911621,
      "learning_rate": 4.388511204632927e-05,
      "loss": 0.2731,
      "step": 3900
    },
    {
      "epoch": 0.14133776191654004,
      "grad_norm": 16.495195388793945,
      "learning_rate": 4.370526240063307e-05,
      "loss": 0.2837,
      "step": 4000
    },
    {
      "epoch": 0.14487120596445355,
      "grad_norm": 9.13233757019043,
      "learning_rate": 4.352541275493687e-05,
      "loss": 0.2847,
      "step": 4100
    },
    {
      "epoch": 0.14840465001236705,
      "grad_norm": 19.140413284301758,
      "learning_rate": 4.334556310924068e-05,
      "loss": 0.2779,
      "step": 4200
    },
    {
      "epoch": 0.15193809406028055,
      "grad_norm": 6.870297908782959,
      "learning_rate": 4.3165713463544474e-05,
      "loss": 0.2791,
      "step": 4300
    },
    {
      "epoch": 0.15547153810819406,
      "grad_norm": 15.353680610656738,
      "learning_rate": 4.298586381784828e-05,
      "loss": 0.2655,
      "step": 4400
    },
    {
      "epoch": 0.15900498215610756,
      "grad_norm": 7.435111045837402,
      "learning_rate": 4.280601417215208e-05,
      "loss": 0.2683,
      "step": 4500
    },
    {
      "epoch": 0.16253842620402106,
      "grad_norm": 3.588559865951538,
      "learning_rate": 4.262616452645588e-05,
      "loss": 0.2596,
      "step": 4600
    },
    {
      "epoch": 0.16607187025193457,
      "grad_norm": 8.34006404876709,
      "learning_rate": 4.2446314880759684e-05,
      "loss": 0.2575,
      "step": 4700
    },
    {
      "epoch": 0.16960531429984807,
      "grad_norm": 8.426225662231445,
      "learning_rate": 4.226646523506349e-05,
      "loss": 0.2682,
      "step": 4800
    },
    {
      "epoch": 0.17313875834776157,
      "grad_norm": 4.7764716148376465,
      "learning_rate": 4.208661558936729e-05,
      "loss": 0.2682,
      "step": 4900
    },
    {
      "epoch": 0.17667220239567508,
      "grad_norm": 4.6285505294799805,
      "learning_rate": 4.190676594367109e-05,
      "loss": 0.2694,
      "step": 5000
    },
    {
      "epoch": 0.18020564644358858,
      "grad_norm": 19.49005889892578,
      "learning_rate": 4.1726916297974894e-05,
      "loss": 0.2542,
      "step": 5100
    },
    {
      "epoch": 0.18373909049150206,
      "grad_norm": 11.505105972290039,
      "learning_rate": 4.15470666522787e-05,
      "loss": 0.2505,
      "step": 5200
    },
    {
      "epoch": 0.18727253453941556,
      "grad_norm": 12.676939010620117,
      "learning_rate": 4.1367217006582495e-05,
      "loss": 0.2569,
      "step": 5300
    },
    {
      "epoch": 0.19080597858732906,
      "grad_norm": 19.799047470092773,
      "learning_rate": 4.11873673608863e-05,
      "loss": 0.249,
      "step": 5400
    },
    {
      "epoch": 0.19433942263524256,
      "grad_norm": 9.153903007507324,
      "learning_rate": 4.1007517715190104e-05,
      "loss": 0.2574,
      "step": 5500
    },
    {
      "epoch": 0.19787286668315607,
      "grad_norm": 9.515861511230469,
      "learning_rate": 4.0827668069493905e-05,
      "loss": 0.2637,
      "step": 5600
    },
    {
      "epoch": 0.20140631073106957,
      "grad_norm": 7.586848258972168,
      "learning_rate": 4.0647818423797705e-05,
      "loss": 0.2653,
      "step": 5700
    },
    {
      "epoch": 0.20493975477898307,
      "grad_norm": 4.114897727966309,
      "learning_rate": 4.046796877810151e-05,
      "loss": 0.2632,
      "step": 5800
    },
    {
      "epoch": 0.20847319882689658,
      "grad_norm": 4.707144737243652,
      "learning_rate": 4.0288119132405314e-05,
      "loss": 0.2535,
      "step": 5900
    },
    {
      "epoch": 0.21200664287481008,
      "grad_norm": 7.066754341125488,
      "learning_rate": 4.0108269486709115e-05,
      "loss": 0.2422,
      "step": 6000
    },
    {
      "epoch": 0.21554008692272358,
      "grad_norm": 10.034825325012207,
      "learning_rate": 3.9928419841012915e-05,
      "loss": 0.2378,
      "step": 6100
    },
    {
      "epoch": 0.2190735309706371,
      "grad_norm": 3.8835277557373047,
      "learning_rate": 3.9748570195316716e-05,
      "loss": 0.2525,
      "step": 6200
    },
    {
      "epoch": 0.2226069750185506,
      "grad_norm": 3.97147274017334,
      "learning_rate": 3.956872054962052e-05,
      "loss": 0.2359,
      "step": 6300
    },
    {
      "epoch": 0.2261404190664641,
      "grad_norm": 11.10617446899414,
      "learning_rate": 3.938887090392432e-05,
      "loss": 0.2662,
      "step": 6400
    },
    {
      "epoch": 0.2296738631143776,
      "grad_norm": 8.734230995178223,
      "learning_rate": 3.9209021258228125e-05,
      "loss": 0.2473,
      "step": 6500
    },
    {
      "epoch": 0.23320730716229107,
      "grad_norm": 2.453723192214966,
      "learning_rate": 3.9029171612531926e-05,
      "loss": 0.2473,
      "step": 6600
    },
    {
      "epoch": 0.23674075121020458,
      "grad_norm": 6.24397087097168,
      "learning_rate": 3.884932196683573e-05,
      "loss": 0.2409,
      "step": 6700
    },
    {
      "epoch": 0.24027419525811808,
      "grad_norm": 5.227469444274902,
      "learning_rate": 3.866947232113953e-05,
      "loss": 0.2532,
      "step": 6800
    },
    {
      "epoch": 0.24380763930603158,
      "grad_norm": 4.758561134338379,
      "learning_rate": 3.848962267544333e-05,
      "loss": 0.2423,
      "step": 6900
    },
    {
      "epoch": 0.24734108335394508,
      "grad_norm": 11.382200241088867,
      "learning_rate": 3.830977302974713e-05,
      "loss": 0.2431,
      "step": 7000
    },
    {
      "epoch": 0.2508745274018586,
      "grad_norm": 10.716712951660156,
      "learning_rate": 3.812992338405094e-05,
      "loss": 0.2507,
      "step": 7100
    },
    {
      "epoch": 0.2544079714497721,
      "grad_norm": 7.102797508239746,
      "learning_rate": 3.795007373835474e-05,
      "loss": 0.2392,
      "step": 7200
    },
    {
      "epoch": 0.25794141549768557,
      "grad_norm": 16.990215301513672,
      "learning_rate": 3.777022409265854e-05,
      "loss": 0.2513,
      "step": 7300
    },
    {
      "epoch": 0.26147485954559907,
      "grad_norm": 12.654658317565918,
      "learning_rate": 3.759037444696234e-05,
      "loss": 0.2347,
      "step": 7400
    },
    {
      "epoch": 0.2650083035935126,
      "grad_norm": 5.472880840301514,
      "learning_rate": 3.741052480126615e-05,
      "loss": 0.2347,
      "step": 7500
    },
    {
      "epoch": 0.2685417476414261,
      "grad_norm": 8.967240333557129,
      "learning_rate": 3.723067515556994e-05,
      "loss": 0.2211,
      "step": 7600
    },
    {
      "epoch": 0.2720751916893396,
      "grad_norm": 8.058796882629395,
      "learning_rate": 3.705082550987375e-05,
      "loss": 0.2428,
      "step": 7700
    },
    {
      "epoch": 0.2756086357372531,
      "grad_norm": 10.651857376098633,
      "learning_rate": 3.687097586417755e-05,
      "loss": 0.2431,
      "step": 7800
    },
    {
      "epoch": 0.2791420797851666,
      "grad_norm": 16.79781150817871,
      "learning_rate": 3.669112621848135e-05,
      "loss": 0.25,
      "step": 7900
    },
    {
      "epoch": 0.2826755238330801,
      "grad_norm": 2.9585721492767334,
      "learning_rate": 3.651127657278515e-05,
      "loss": 0.2428,
      "step": 8000
    },
    {
      "epoch": 0.2862089678809936,
      "grad_norm": 3.9895827770233154,
      "learning_rate": 3.633142692708896e-05,
      "loss": 0.2591,
      "step": 8100
    },
    {
      "epoch": 0.2897424119289071,
      "grad_norm": 19.54746437072754,
      "learning_rate": 3.615157728139276e-05,
      "loss": 0.2399,
      "step": 8200
    },
    {
      "epoch": 0.2932758559768206,
      "grad_norm": 13.406783103942871,
      "learning_rate": 3.597172763569656e-05,
      "loss": 0.2383,
      "step": 8300
    },
    {
      "epoch": 0.2968093000247341,
      "grad_norm": 3.0260884761810303,
      "learning_rate": 3.579187799000036e-05,
      "loss": 0.2538,
      "step": 8400
    },
    {
      "epoch": 0.3003427440726476,
      "grad_norm": 9.180882453918457,
      "learning_rate": 3.561202834430417e-05,
      "loss": 0.2646,
      "step": 8500
    },
    {
      "epoch": 0.3038761881205611,
      "grad_norm": 4.332892417907715,
      "learning_rate": 3.543217869860796e-05,
      "loss": 0.2334,
      "step": 8600
    },
    {
      "epoch": 0.3074096321684746,
      "grad_norm": 5.419953346252441,
      "learning_rate": 3.525232905291177e-05,
      "loss": 0.2372,
      "step": 8700
    },
    {
      "epoch": 0.3109430762163881,
      "grad_norm": 5.961595058441162,
      "learning_rate": 3.507247940721557e-05,
      "loss": 0.2386,
      "step": 8800
    },
    {
      "epoch": 0.3144765202643016,
      "grad_norm": 7.420506954193115,
      "learning_rate": 3.489262976151937e-05,
      "loss": 0.2407,
      "step": 8900
    },
    {
      "epoch": 0.3180099643122151,
      "grad_norm": 5.556256294250488,
      "learning_rate": 3.471278011582317e-05,
      "loss": 0.2267,
      "step": 9000
    },
    {
      "epoch": 0.3215434083601286,
      "grad_norm": 11.86214542388916,
      "learning_rate": 3.4532930470126974e-05,
      "loss": 0.2195,
      "step": 9100
    },
    {
      "epoch": 0.3250768524080421,
      "grad_norm": 3.719926118850708,
      "learning_rate": 3.435308082443078e-05,
      "loss": 0.2381,
      "step": 9200
    },
    {
      "epoch": 0.32861029645595563,
      "grad_norm": 3.126859426498413,
      "learning_rate": 3.4173231178734575e-05,
      "loss": 0.2433,
      "step": 9300
    },
    {
      "epoch": 0.33214374050386913,
      "grad_norm": 7.612851619720459,
      "learning_rate": 3.399338153303838e-05,
      "loss": 0.2374,
      "step": 9400
    },
    {
      "epoch": 0.33567718455178264,
      "grad_norm": 3.519158124923706,
      "learning_rate": 3.3813531887342184e-05,
      "loss": 0.2241,
      "step": 9500
    },
    {
      "epoch": 0.33921062859969614,
      "grad_norm": 4.3275885581970215,
      "learning_rate": 3.3633682241645984e-05,
      "loss": 0.2349,
      "step": 9600
    },
    {
      "epoch": 0.34274407264760964,
      "grad_norm": 25.472366333007812,
      "learning_rate": 3.3453832595949785e-05,
      "loss": 0.2248,
      "step": 9700
    },
    {
      "epoch": 0.34627751669552315,
      "grad_norm": 10.451841354370117,
      "learning_rate": 3.327398295025359e-05,
      "loss": 0.2526,
      "step": 9800
    },
    {
      "epoch": 0.34981096074343665,
      "grad_norm": 10.65050983428955,
      "learning_rate": 3.309413330455739e-05,
      "loss": 0.229,
      "step": 9900
    },
    {
      "epoch": 0.35334440479135015,
      "grad_norm": 4.248900413513184,
      "learning_rate": 3.2914283658861194e-05,
      "loss": 0.2502,
      "step": 10000
    },
    {
      "epoch": 0.35687784883926366,
      "grad_norm": 2.850713014602661,
      "learning_rate": 3.2734434013164995e-05,
      "loss": 0.2442,
      "step": 10100
    },
    {
      "epoch": 0.36041129288717716,
      "grad_norm": 4.421992778778076,
      "learning_rate": 3.2554584367468796e-05,
      "loss": 0.2287,
      "step": 10200
    },
    {
      "epoch": 0.3639447369350906,
      "grad_norm": 4.956003665924072,
      "learning_rate": 3.23747347217726e-05,
      "loss": 0.2314,
      "step": 10300
    },
    {
      "epoch": 0.3674781809830041,
      "grad_norm": 6.866689682006836,
      "learning_rate": 3.2194885076076404e-05,
      "loss": 0.2259,
      "step": 10400
    },
    {
      "epoch": 0.3710116250309176,
      "grad_norm": 6.94300651550293,
      "learning_rate": 3.2015035430380205e-05,
      "loss": 0.2285,
      "step": 10500
    },
    {
      "epoch": 0.3745450690788311,
      "grad_norm": 19.86452865600586,
      "learning_rate": 3.1835185784684006e-05,
      "loss": 0.229,
      "step": 10600
    },
    {
      "epoch": 0.3780785131267446,
      "grad_norm": 15.630905151367188,
      "learning_rate": 3.165533613898781e-05,
      "loss": 0.2274,
      "step": 10700
    },
    {
      "epoch": 0.3816119571746581,
      "grad_norm": 3.808868885040283,
      "learning_rate": 3.1475486493291614e-05,
      "loss": 0.2298,
      "step": 10800
    },
    {
      "epoch": 0.3851454012225716,
      "grad_norm": 4.784353733062744,
      "learning_rate": 3.129563684759541e-05,
      "loss": 0.2346,
      "step": 10900
    },
    {
      "epoch": 0.38867884527048513,
      "grad_norm": 14.149474143981934,
      "learning_rate": 3.1115787201899216e-05,
      "loss": 0.2218,
      "step": 11000
    },
    {
      "epoch": 0.39221228931839863,
      "grad_norm": 8.039393424987793,
      "learning_rate": 3.093593755620302e-05,
      "loss": 0.2401,
      "step": 11100
    },
    {
      "epoch": 0.39574573336631214,
      "grad_norm": 11.174625396728516,
      "learning_rate": 3.075608791050682e-05,
      "loss": 0.2372,
      "step": 11200
    },
    {
      "epoch": 0.39927917741422564,
      "grad_norm": 5.572368621826172,
      "learning_rate": 3.057623826481062e-05,
      "loss": 0.2259,
      "step": 11300
    },
    {
      "epoch": 0.40281262146213914,
      "grad_norm": 9.320554733276367,
      "learning_rate": 3.0396388619114423e-05,
      "loss": 0.235,
      "step": 11400
    },
    {
      "epoch": 0.40634606551005265,
      "grad_norm": 8.423247337341309,
      "learning_rate": 3.0216538973418223e-05,
      "loss": 0.2287,
      "step": 11500
    },
    {
      "epoch": 0.40987950955796615,
      "grad_norm": 4.507028102874756,
      "learning_rate": 3.0036689327722028e-05,
      "loss": 0.2226,
      "step": 11600
    },
    {
      "epoch": 0.41341295360587965,
      "grad_norm": 4.214542865753174,
      "learning_rate": 2.985683968202583e-05,
      "loss": 0.2378,
      "step": 11700
    },
    {
      "epoch": 0.41694639765379315,
      "grad_norm": 10.8181734085083,
      "learning_rate": 2.9676990036329626e-05,
      "loss": 0.2038,
      "step": 11800
    },
    {
      "epoch": 0.42047984170170666,
      "grad_norm": 11.119644165039062,
      "learning_rate": 2.9497140390633433e-05,
      "loss": 0.2197,
      "step": 11900
    },
    {
      "epoch": 0.42401328574962016,
      "grad_norm": 4.605712890625,
      "learning_rate": 2.931729074493723e-05,
      "loss": 0.2324,
      "step": 12000
    },
    {
      "epoch": 0.42754672979753366,
      "grad_norm": 7.408802509307861,
      "learning_rate": 2.9137441099241035e-05,
      "loss": 0.2314,
      "step": 12100
    },
    {
      "epoch": 0.43108017384544717,
      "grad_norm": 4.719128608703613,
      "learning_rate": 2.8957591453544836e-05,
      "loss": 0.2293,
      "step": 12200
    },
    {
      "epoch": 0.43461361789336067,
      "grad_norm": 10.38821029663086,
      "learning_rate": 2.877774180784864e-05,
      "loss": 0.2205,
      "step": 12300
    },
    {
      "epoch": 0.4381470619412742,
      "grad_norm": 4.473766803741455,
      "learning_rate": 2.859789216215244e-05,
      "loss": 0.2529,
      "step": 12400
    },
    {
      "epoch": 0.4416805059891877,
      "grad_norm": 3.1899235248565674,
      "learning_rate": 2.8418042516456245e-05,
      "loss": 0.2325,
      "step": 12500
    }
  ],
  "logging_steps": 100,
  "max_steps": 28301,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 10,
  "trial_name": null,
  "trial_params": null
}
