{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005,
      "grad_norm": 19.150697708129883,
      "learning_rate": 0.000125,
      "loss": 6.3528,
      "step": 25
    },
    {
      "epoch": 0.01,
      "grad_norm": 13.477229118347168,
      "learning_rate": 0.00025,
      "loss": 2.7257,
      "step": 50
    },
    {
      "epoch": 0.015,
      "grad_norm": 2.348761796951294,
      "learning_rate": 0.000375,
      "loss": 0.3832,
      "step": 75
    },
    {
      "epoch": 0.02,
      "grad_norm": 13.569649696350098,
      "learning_rate": 0.0005,
      "loss": 0.395,
      "step": 100
    },
    {
      "epoch": 0.025,
      "grad_norm": 2.987781524658203,
      "learning_rate": 0.0004974489795918367,
      "loss": 0.3245,
      "step": 125
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.9859113693237305,
      "learning_rate": 0.0004948979591836735,
      "loss": 0.3968,
      "step": 150
    },
    {
      "epoch": 0.035,
      "grad_norm": 7.027774810791016,
      "learning_rate": 0.0004923469387755102,
      "loss": 0.372,
      "step": 175
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.2613275051116943,
      "learning_rate": 0.0004897959183673469,
      "loss": 0.3553,
      "step": 200
    },
    {
      "epoch": 0.045,
      "grad_norm": 2.91735577583313,
      "learning_rate": 0.0004872448979591837,
      "loss": 0.3464,
      "step": 225
    },
    {
      "epoch": 0.05,
      "grad_norm": 5.013142108917236,
      "learning_rate": 0.0004846938775510204,
      "loss": 0.384,
      "step": 250
    },
    {
      "epoch": 0.055,
      "grad_norm": 1.8648736476898193,
      "learning_rate": 0.00048214285714285715,
      "loss": 0.3453,
      "step": 275
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.4175996780395508,
      "learning_rate": 0.00047959183673469387,
      "loss": 0.3498,
      "step": 300
    },
    {
      "epoch": 0.065,
      "grad_norm": 1.3433836698532104,
      "learning_rate": 0.00047704081632653065,
      "loss": 0.3328,
      "step": 325
    },
    {
      "epoch": 0.07,
      "grad_norm": 6.251605033874512,
      "learning_rate": 0.0004744897959183674,
      "loss": 0.3481,
      "step": 350
    },
    {
      "epoch": 0.075,
      "grad_norm": 8.142577171325684,
      "learning_rate": 0.0004719387755102041,
      "loss": 0.3605,
      "step": 375
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.3646539449691772,
      "learning_rate": 0.00046938775510204083,
      "loss": 0.3449,
      "step": 400
    },
    {
      "epoch": 0.085,
      "grad_norm": 1.8183035850524902,
      "learning_rate": 0.00046683673469387755,
      "loss": 0.3153,
      "step": 425
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.100299119949341,
      "learning_rate": 0.00046428571428571433,
      "loss": 0.3616,
      "step": 450
    },
    {
      "epoch": 0.095,
      "grad_norm": 3.516753673553467,
      "learning_rate": 0.000461734693877551,
      "loss": 0.3593,
      "step": 475
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.1734696626663208,
      "learning_rate": 0.0004591836734693878,
      "loss": 0.336,
      "step": 500
    },
    {
      "epoch": 0.105,
      "grad_norm": 1.229257583618164,
      "learning_rate": 0.00045663265306122446,
      "loss": 0.3719,
      "step": 525
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.6197941303253174,
      "learning_rate": 0.00045408163265306124,
      "loss": 0.3707,
      "step": 550
    },
    {
      "epoch": 0.115,
      "grad_norm": 1.4932106733322144,
      "learning_rate": 0.00045153061224489796,
      "loss": 0.3423,
      "step": 575
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.9075515270233154,
      "learning_rate": 0.0004489795918367347,
      "loss": 0.3323,
      "step": 600
    },
    {
      "epoch": 0.125,
      "grad_norm": 7.876760005950928,
      "learning_rate": 0.00044642857142857147,
      "loss": 0.3208,
      "step": 625
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.3457183837890625,
      "learning_rate": 0.00044387755102040814,
      "loss": 0.315,
      "step": 650
    },
    {
      "epoch": 0.135,
      "grad_norm": 6.0750932693481445,
      "learning_rate": 0.0004413265306122449,
      "loss": 0.3244,
      "step": 675
    },
    {
      "epoch": 0.14,
      "grad_norm": 6.751211643218994,
      "learning_rate": 0.00043877551020408165,
      "loss": 0.3116,
      "step": 700
    },
    {
      "epoch": 0.145,
      "grad_norm": 2.9248688220977783,
      "learning_rate": 0.00043622448979591837,
      "loss": 0.2923,
      "step": 725
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2638825178146362,
      "learning_rate": 0.0004336734693877551,
      "loss": 0.3074,
      "step": 750
    },
    {
      "epoch": 0.155,
      "grad_norm": 2.0921521186828613,
      "learning_rate": 0.0004311224489795919,
      "loss": 0.3057,
      "step": 775
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.543713569641113,
      "learning_rate": 0.00042857142857142855,
      "loss": 0.302,
      "step": 800
    },
    {
      "epoch": 0.165,
      "grad_norm": 5.0661468505859375,
      "learning_rate": 0.00042602040816326533,
      "loss": 0.2999,
      "step": 825
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0910710096359253,
      "learning_rate": 0.00042346938775510206,
      "loss": 0.2707,
      "step": 850
    },
    {
      "epoch": 0.175,
      "grad_norm": 7.579481601715088,
      "learning_rate": 0.0004209183673469388,
      "loss": 0.2869,
      "step": 875
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.6830096244812012,
      "learning_rate": 0.00041836734693877556,
      "loss": 0.2746,
      "step": 900
    },
    {
      "epoch": 0.185,
      "grad_norm": 1.5958069562911987,
      "learning_rate": 0.00041581632653061223,
      "loss": 0.2981,
      "step": 925
    },
    {
      "epoch": 0.19,
      "grad_norm": 6.490472793579102,
      "learning_rate": 0.000413265306122449,
      "loss": 0.2908,
      "step": 950
    },
    {
      "epoch": 0.195,
      "grad_norm": 4.198654651641846,
      "learning_rate": 0.0004107142857142857,
      "loss": 0.2849,
      "step": 975
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.6124987602233887,
      "learning_rate": 0.00040816326530612246,
      "loss": 0.2484,
      "step": 1000
    },
    {
      "epoch": 0.205,
      "grad_norm": 7.213009357452393,
      "learning_rate": 0.0004056122448979592,
      "loss": 0.2955,
      "step": 1025
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.763549566268921,
      "learning_rate": 0.0004030612244897959,
      "loss": 0.2715,
      "step": 1050
    },
    {
      "epoch": 0.215,
      "grad_norm": 1.6108877658843994,
      "learning_rate": 0.00040051020408163264,
      "loss": 0.2757,
      "step": 1075
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.728667736053467,
      "learning_rate": 0.00039795918367346937,
      "loss": 0.2904,
      "step": 1100
    },
    {
      "epoch": 0.225,
      "grad_norm": 1.891976237297058,
      "learning_rate": 0.00039540816326530615,
      "loss": 0.2746,
      "step": 1125
    },
    {
      "epoch": 0.23,
      "grad_norm": 4.952478885650635,
      "learning_rate": 0.0003928571428571429,
      "loss": 0.247,
      "step": 1150
    },
    {
      "epoch": 0.235,
      "grad_norm": 3.0083463191986084,
      "learning_rate": 0.0003903061224489796,
      "loss": 0.2637,
      "step": 1175
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.6921714544296265,
      "learning_rate": 0.0003877551020408163,
      "loss": 0.3528,
      "step": 1200
    },
    {
      "epoch": 0.245,
      "grad_norm": 5.35463285446167,
      "learning_rate": 0.0003852040816326531,
      "loss": 0.2614,
      "step": 1225
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.568006753921509,
      "learning_rate": 0.0003826530612244898,
      "loss": 0.2977,
      "step": 1250
    },
    {
      "epoch": 0.255,
      "grad_norm": 1.4275680780410767,
      "learning_rate": 0.00038010204081632656,
      "loss": 0.2554,
      "step": 1275
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.7258191108703613,
      "learning_rate": 0.00037755102040816323,
      "loss": 0.2557,
      "step": 1300
    },
    {
      "epoch": 0.265,
      "grad_norm": 1.8603256940841675,
      "learning_rate": 0.000375,
      "loss": 0.2676,
      "step": 1325
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.1284099817276,
      "learning_rate": 0.0003724489795918368,
      "loss": 0.287,
      "step": 1350
    },
    {
      "epoch": 0.275,
      "grad_norm": 1.7153817415237427,
      "learning_rate": 0.00036989795918367346,
      "loss": 0.2858,
      "step": 1375
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.6437840461730957,
      "learning_rate": 0.00036734693877551024,
      "loss": 0.2646,
      "step": 1400
    },
    {
      "epoch": 0.285,
      "grad_norm": 3.910907030105591,
      "learning_rate": 0.0003647959183673469,
      "loss": 0.2834,
      "step": 1425
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.0340652465820312,
      "learning_rate": 0.0003622448979591837,
      "loss": 0.3302,
      "step": 1450
    },
    {
      "epoch": 0.295,
      "grad_norm": 1.2508234977722168,
      "learning_rate": 0.0003596938775510204,
      "loss": 0.2701,
      "step": 1475
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1411694288253784,
      "learning_rate": 0.00035714285714285714,
      "loss": 0.2363,
      "step": 1500
    },
    {
      "epoch": 0.305,
      "grad_norm": 1.8675907850265503,
      "learning_rate": 0.00035459183673469387,
      "loss": 0.2672,
      "step": 1525
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.91085684299469,
      "learning_rate": 0.00035204081632653065,
      "loss": 0.287,
      "step": 1550
    },
    {
      "epoch": 0.315,
      "grad_norm": 5.721397399902344,
      "learning_rate": 0.0003494897959183674,
      "loss": 0.2727,
      "step": 1575
    },
    {
      "epoch": 0.32,
      "grad_norm": 5.097988128662109,
      "learning_rate": 0.0003469387755102041,
      "loss": 0.2638,
      "step": 1600
    },
    {
      "epoch": 0.325,
      "grad_norm": 8.83723258972168,
      "learning_rate": 0.0003443877551020408,
      "loss": 0.2333,
      "step": 1625
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.870885133743286,
      "learning_rate": 0.00034183673469387755,
      "loss": 0.2509,
      "step": 1650
    },
    {
      "epoch": 0.335,
      "grad_norm": 4.930182933807373,
      "learning_rate": 0.00033928571428571433,
      "loss": 0.2585,
      "step": 1675
    },
    {
      "epoch": 0.34,
      "grad_norm": 6.479826927185059,
      "learning_rate": 0.000336734693877551,
      "loss": 0.2437,
      "step": 1700
    },
    {
      "epoch": 0.345,
      "grad_norm": 4.194431781768799,
      "learning_rate": 0.0003341836734693878,
      "loss": 0.2911,
      "step": 1725
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.1528217792510986,
      "learning_rate": 0.00033163265306122445,
      "loss": 0.2396,
      "step": 1750
    },
    {
      "epoch": 0.355,
      "grad_norm": 3.1427204608917236,
      "learning_rate": 0.00032908163265306123,
      "loss": 0.248,
      "step": 1775
    },
    {
      "epoch": 0.36,
      "grad_norm": 6.4365339279174805,
      "learning_rate": 0.00032653061224489796,
      "loss": 0.2694,
      "step": 1800
    },
    {
      "epoch": 0.365,
      "grad_norm": 2.8075666427612305,
      "learning_rate": 0.0003239795918367347,
      "loss": 0.2861,
      "step": 1825
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.243788480758667,
      "learning_rate": 0.00032142857142857147,
      "loss": 0.2538,
      "step": 1850
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.7291784286499023,
      "learning_rate": 0.00031887755102040814,
      "loss": 0.265,
      "step": 1875
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.9566755294799805,
      "learning_rate": 0.0003163265306122449,
      "loss": 0.2668,
      "step": 1900
    },
    {
      "epoch": 0.385,
      "grad_norm": 5.6226348876953125,
      "learning_rate": 0.00031377551020408164,
      "loss": 0.2561,
      "step": 1925
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.392033815383911,
      "learning_rate": 0.00031122448979591837,
      "loss": 0.2568,
      "step": 1950
    },
    {
      "epoch": 0.395,
      "grad_norm": 1.020897626876831,
      "learning_rate": 0.0003086734693877551,
      "loss": 0.2789,
      "step": 1975
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.460311412811279,
      "learning_rate": 0.0003061224489795919,
      "loss": 0.2782,
      "step": 2000
    },
    {
      "epoch": 0.405,
      "grad_norm": 1.204355001449585,
      "learning_rate": 0.00030357142857142855,
      "loss": 0.2335,
      "step": 2025
    },
    {
      "epoch": 0.41,
      "grad_norm": 5.475181579589844,
      "learning_rate": 0.0003010204081632653,
      "loss": 0.2593,
      "step": 2050
    },
    {
      "epoch": 0.415,
      "grad_norm": 1.8858927488327026,
      "learning_rate": 0.00029846938775510205,
      "loss": 0.2414,
      "step": 2075
    },
    {
      "epoch": 0.42,
      "grad_norm": 4.007383346557617,
      "learning_rate": 0.0002959183673469388,
      "loss": 0.2302,
      "step": 2100
    },
    {
      "epoch": 0.425,
      "grad_norm": 1.8661198616027832,
      "learning_rate": 0.00029336734693877556,
      "loss": 0.221,
      "step": 2125
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.100148916244507,
      "learning_rate": 0.00029081632653061223,
      "loss": 0.2678,
      "step": 2150
    },
    {
      "epoch": 0.435,
      "grad_norm": 9.437960624694824,
      "learning_rate": 0.000288265306122449,
      "loss": 0.2702,
      "step": 2175
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.609684705734253,
      "learning_rate": 0.0002857142857142857,
      "loss": 0.2735,
      "step": 2200
    },
    {
      "epoch": 0.445,
      "grad_norm": 3.781806230545044,
      "learning_rate": 0.00028316326530612246,
      "loss": 0.2791,
      "step": 2225
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.126014471054077,
      "learning_rate": 0.0002806122448979592,
      "loss": 0.301,
      "step": 2250
    },
    {
      "epoch": 0.455,
      "grad_norm": 3.0870473384857178,
      "learning_rate": 0.0002780612244897959,
      "loss": 0.246,
      "step": 2275
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.7860422134399414,
      "learning_rate": 0.00027551020408163264,
      "loss": 0.2393,
      "step": 2300
    },
    {
      "epoch": 0.465,
      "grad_norm": 2.561419725418091,
      "learning_rate": 0.00027295918367346936,
      "loss": 0.2451,
      "step": 2325
    },
    {
      "epoch": 0.47,
      "grad_norm": 4.17231559753418,
      "learning_rate": 0.00027040816326530614,
      "loss": 0.2954,
      "step": 2350
    },
    {
      "epoch": 0.475,
      "grad_norm": 4.930899620056152,
      "learning_rate": 0.00026785714285714287,
      "loss": 0.2396,
      "step": 2375
    },
    {
      "epoch": 0.48,
      "grad_norm": 5.0382232666015625,
      "learning_rate": 0.0002653061224489796,
      "loss": 0.2674,
      "step": 2400
    },
    {
      "epoch": 0.485,
      "grad_norm": 1.461022973060608,
      "learning_rate": 0.0002627551020408163,
      "loss": 0.2318,
      "step": 2425
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.389538288116455,
      "learning_rate": 0.0002602040816326531,
      "loss": 0.276,
      "step": 2450
    },
    {
      "epoch": 0.495,
      "grad_norm": 1.0829079151153564,
      "learning_rate": 0.0002576530612244898,
      "loss": 0.1996,
      "step": 2475
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.6196027994155884,
      "learning_rate": 0.00025510204081632655,
      "loss": 0.2167,
      "step": 2500
    }
  ],
  "logging_steps": 25,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 10,
  "trial_name": null,
  "trial_params": null
}
