{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.24734108335394508,
  "eval_steps": 500,
  "global_step": 7000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0035334440479135015,
      "grad_norm": 11.242419242858887,
      "learning_rate": 1e-05,
      "loss": 6.9178,
      "step": 100
    },
    {
      "epoch": 0.007066888095827003,
      "grad_norm": 8.21684741973877,
      "learning_rate": 2e-05,
      "loss": 5.2158,
      "step": 200
    },
    {
      "epoch": 0.010600332143740504,
      "grad_norm": 18.501537322998047,
      "learning_rate": 3e-05,
      "loss": 2.2816,
      "step": 300
    },
    {
      "epoch": 0.014133776191654006,
      "grad_norm": 13.512194633483887,
      "learning_rate": 4e-05,
      "loss": 0.4146,
      "step": 400
    },
    {
      "epoch": 0.017667220239567506,
      "grad_norm": 7.186823844909668,
      "learning_rate": 5e-05,
      "loss": 0.3584,
      "step": 500
    },
    {
      "epoch": 0.02120066428748101,
      "grad_norm": 3.991400718688965,
      "learning_rate": 4.98201503543038e-05,
      "loss": 0.3586,
      "step": 600
    },
    {
      "epoch": 0.02473410833539451,
      "grad_norm": 5.979557037353516,
      "learning_rate": 4.9640300708607604e-05,
      "loss": 0.3381,
      "step": 700
    },
    {
      "epoch": 0.02826755238330801,
      "grad_norm": 3.350285291671753,
      "learning_rate": 4.9460451062911405e-05,
      "loss": 0.345,
      "step": 800
    },
    {
      "epoch": 0.031800996431221515,
      "grad_norm": 6.983935832977295,
      "learning_rate": 4.928060141721521e-05,
      "loss": 0.3384,
      "step": 900
    },
    {
      "epoch": 0.03533444047913501,
      "grad_norm": 5.302139759063721,
      "learning_rate": 4.910075177151901e-05,
      "loss": 0.3293,
      "step": 1000
    },
    {
      "epoch": 0.038867884527048514,
      "grad_norm": 13.931511878967285,
      "learning_rate": 4.8920902125822814e-05,
      "loss": 0.3373,
      "step": 1100
    },
    {
      "epoch": 0.04240132857496202,
      "grad_norm": 2.848280191421509,
      "learning_rate": 4.8741052480126615e-05,
      "loss": 0.3302,
      "step": 1200
    },
    {
      "epoch": 0.045934772622875514,
      "grad_norm": 4.866534233093262,
      "learning_rate": 4.856120283443042e-05,
      "loss": 0.3267,
      "step": 1300
    },
    {
      "epoch": 0.04946821667078902,
      "grad_norm": 3.659559488296509,
      "learning_rate": 4.8381353188734216e-05,
      "loss": 0.3226,
      "step": 1400
    },
    {
      "epoch": 0.05300166071870252,
      "grad_norm": 3.1809144020080566,
      "learning_rate": 4.8201503543038024e-05,
      "loss": 0.3252,
      "step": 1500
    },
    {
      "epoch": 0.05653510476661602,
      "grad_norm": 5.5572028160095215,
      "learning_rate": 4.8021653897341825e-05,
      "loss": 0.3148,
      "step": 1600
    },
    {
      "epoch": 0.06006854881452952,
      "grad_norm": 26.186689376831055,
      "learning_rate": 4.7841804251645626e-05,
      "loss": 0.3178,
      "step": 1700
    },
    {
      "epoch": 0.06360199286244303,
      "grad_norm": 16.540754318237305,
      "learning_rate": 4.7661954605949426e-05,
      "loss": 0.3199,
      "step": 1800
    },
    {
      "epoch": 0.06713543691035652,
      "grad_norm": 3.7190308570861816,
      "learning_rate": 4.7482104960253234e-05,
      "loss": 0.3198,
      "step": 1900
    },
    {
      "epoch": 0.07066888095827002,
      "grad_norm": 19.312763214111328,
      "learning_rate": 4.730225531455703e-05,
      "loss": 0.3208,
      "step": 2000
    },
    {
      "epoch": 0.07420232500618353,
      "grad_norm": 8.05016040802002,
      "learning_rate": 4.7122405668860836e-05,
      "loss": 0.3302,
      "step": 2100
    },
    {
      "epoch": 0.07773576905409703,
      "grad_norm": 9.219091415405273,
      "learning_rate": 4.6942556023164636e-05,
      "loss": 0.3152,
      "step": 2200
    },
    {
      "epoch": 0.08126921310201053,
      "grad_norm": 3.501424789428711,
      "learning_rate": 4.676270637746844e-05,
      "loss": 0.3097,
      "step": 2300
    },
    {
      "epoch": 0.08480265714992404,
      "grad_norm": 11.660674095153809,
      "learning_rate": 4.658285673177224e-05,
      "loss": 0.3059,
      "step": 2400
    },
    {
      "epoch": 0.08833610119783754,
      "grad_norm": 3.1868367195129395,
      "learning_rate": 4.6403007086076046e-05,
      "loss": 0.294,
      "step": 2500
    },
    {
      "epoch": 0.09186954524575103,
      "grad_norm": 7.198179244995117,
      "learning_rate": 4.6223157440379846e-05,
      "loss": 0.3135,
      "step": 2600
    },
    {
      "epoch": 0.09540298929366453,
      "grad_norm": 8.992080688476562,
      "learning_rate": 4.604330779468365e-05,
      "loss": 0.3057,
      "step": 2700
    },
    {
      "epoch": 0.09893643334157803,
      "grad_norm": 2.399609088897705,
      "learning_rate": 4.586345814898745e-05,
      "loss": 0.2937,
      "step": 2800
    },
    {
      "epoch": 0.10246987738949154,
      "grad_norm": 9.025713920593262,
      "learning_rate": 4.5683608503291256e-05,
      "loss": 0.2829,
      "step": 2900
    },
    {
      "epoch": 0.10600332143740504,
      "grad_norm": 5.894839763641357,
      "learning_rate": 4.550375885759505e-05,
      "loss": 0.3057,
      "step": 3000
    },
    {
      "epoch": 0.10953676548531854,
      "grad_norm": 11.53746223449707,
      "learning_rate": 4.532390921189886e-05,
      "loss": 0.2921,
      "step": 3100
    },
    {
      "epoch": 0.11307020953323205,
      "grad_norm": 5.6951799392700195,
      "learning_rate": 4.514405956620266e-05,
      "loss": 0.2974,
      "step": 3200
    },
    {
      "epoch": 0.11660365358114554,
      "grad_norm": 9.74968147277832,
      "learning_rate": 4.496420992050646e-05,
      "loss": 0.2876,
      "step": 3300
    },
    {
      "epoch": 0.12013709762905904,
      "grad_norm": 4.059431552886963,
      "learning_rate": 4.478436027481026e-05,
      "loss": 0.2954,
      "step": 3400
    },
    {
      "epoch": 0.12367054167697254,
      "grad_norm": 11.388775825500488,
      "learning_rate": 4.460451062911406e-05,
      "loss": 0.2898,
      "step": 3500
    },
    {
      "epoch": 0.12720398572488606,
      "grad_norm": 9.650588035583496,
      "learning_rate": 4.442466098341787e-05,
      "loss": 0.2772,
      "step": 3600
    },
    {
      "epoch": 0.13073742977279953,
      "grad_norm": 5.235257625579834,
      "learning_rate": 4.424481133772166e-05,
      "loss": 0.2745,
      "step": 3700
    },
    {
      "epoch": 0.13427087382071304,
      "grad_norm": 7.478841781616211,
      "learning_rate": 4.406496169202547e-05,
      "loss": 0.2842,
      "step": 3800
    },
    {
      "epoch": 0.13780431786862654,
      "grad_norm": 11.058333396911621,
      "learning_rate": 4.388511204632927e-05,
      "loss": 0.2731,
      "step": 3900
    },
    {
      "epoch": 0.14133776191654004,
      "grad_norm": 16.495195388793945,
      "learning_rate": 4.370526240063307e-05,
      "loss": 0.2837,
      "step": 4000
    },
    {
      "epoch": 0.14487120596445355,
      "grad_norm": 9.13233757019043,
      "learning_rate": 4.352541275493687e-05,
      "loss": 0.2847,
      "step": 4100
    },
    {
      "epoch": 0.14840465001236705,
      "grad_norm": 19.140413284301758,
      "learning_rate": 4.334556310924068e-05,
      "loss": 0.2779,
      "step": 4200
    },
    {
      "epoch": 0.15193809406028055,
      "grad_norm": 6.870297908782959,
      "learning_rate": 4.3165713463544474e-05,
      "loss": 0.2791,
      "step": 4300
    },
    {
      "epoch": 0.15547153810819406,
      "grad_norm": 15.353680610656738,
      "learning_rate": 4.298586381784828e-05,
      "loss": 0.2655,
      "step": 4400
    },
    {
      "epoch": 0.15900498215610756,
      "grad_norm": 7.435111045837402,
      "learning_rate": 4.280601417215208e-05,
      "loss": 0.2683,
      "step": 4500
    },
    {
      "epoch": 0.16253842620402106,
      "grad_norm": 3.588559865951538,
      "learning_rate": 4.262616452645588e-05,
      "loss": 0.2596,
      "step": 4600
    },
    {
      "epoch": 0.16607187025193457,
      "grad_norm": 8.34006404876709,
      "learning_rate": 4.2446314880759684e-05,
      "loss": 0.2575,
      "step": 4700
    },
    {
      "epoch": 0.16960531429984807,
      "grad_norm": 8.426225662231445,
      "learning_rate": 4.226646523506349e-05,
      "loss": 0.2682,
      "step": 4800
    },
    {
      "epoch": 0.17313875834776157,
      "grad_norm": 4.7764716148376465,
      "learning_rate": 4.208661558936729e-05,
      "loss": 0.2682,
      "step": 4900
    },
    {
      "epoch": 0.17667220239567508,
      "grad_norm": 4.6285505294799805,
      "learning_rate": 4.190676594367109e-05,
      "loss": 0.2694,
      "step": 5000
    },
    {
      "epoch": 0.18020564644358858,
      "grad_norm": 19.49005889892578,
      "learning_rate": 4.1726916297974894e-05,
      "loss": 0.2542,
      "step": 5100
    },
    {
      "epoch": 0.18373909049150206,
      "grad_norm": 11.505105972290039,
      "learning_rate": 4.15470666522787e-05,
      "loss": 0.2505,
      "step": 5200
    },
    {
      "epoch": 0.18727253453941556,
      "grad_norm": 12.676939010620117,
      "learning_rate": 4.1367217006582495e-05,
      "loss": 0.2569,
      "step": 5300
    },
    {
      "epoch": 0.19080597858732906,
      "grad_norm": 19.799047470092773,
      "learning_rate": 4.11873673608863e-05,
      "loss": 0.249,
      "step": 5400
    },
    {
      "epoch": 0.19433942263524256,
      "grad_norm": 9.153903007507324,
      "learning_rate": 4.1007517715190104e-05,
      "loss": 0.2574,
      "step": 5500
    },
    {
      "epoch": 0.19787286668315607,
      "grad_norm": 9.515861511230469,
      "learning_rate": 4.0827668069493905e-05,
      "loss": 0.2637,
      "step": 5600
    },
    {
      "epoch": 0.20140631073106957,
      "grad_norm": 7.586848258972168,
      "learning_rate": 4.0647818423797705e-05,
      "loss": 0.2653,
      "step": 5700
    },
    {
      "epoch": 0.20493975477898307,
      "grad_norm": 4.114897727966309,
      "learning_rate": 4.046796877810151e-05,
      "loss": 0.2632,
      "step": 5800
    },
    {
      "epoch": 0.20847319882689658,
      "grad_norm": 4.707144737243652,
      "learning_rate": 4.0288119132405314e-05,
      "loss": 0.2535,
      "step": 5900
    },
    {
      "epoch": 0.21200664287481008,
      "grad_norm": 7.066754341125488,
      "learning_rate": 4.0108269486709115e-05,
      "loss": 0.2422,
      "step": 6000
    },
    {
      "epoch": 0.21554008692272358,
      "grad_norm": 10.034825325012207,
      "learning_rate": 3.9928419841012915e-05,
      "loss": 0.2378,
      "step": 6100
    },
    {
      "epoch": 0.2190735309706371,
      "grad_norm": 3.8835277557373047,
      "learning_rate": 3.9748570195316716e-05,
      "loss": 0.2525,
      "step": 6200
    },
    {
      "epoch": 0.2226069750185506,
      "grad_norm": 3.97147274017334,
      "learning_rate": 3.956872054962052e-05,
      "loss": 0.2359,
      "step": 6300
    },
    {
      "epoch": 0.2261404190664641,
      "grad_norm": 11.10617446899414,
      "learning_rate": 3.938887090392432e-05,
      "loss": 0.2662,
      "step": 6400
    },
    {
      "epoch": 0.2296738631143776,
      "grad_norm": 8.734230995178223,
      "learning_rate": 3.9209021258228125e-05,
      "loss": 0.2473,
      "step": 6500
    },
    {
      "epoch": 0.23320730716229107,
      "grad_norm": 2.453723192214966,
      "learning_rate": 3.9029171612531926e-05,
      "loss": 0.2473,
      "step": 6600
    },
    {
      "epoch": 0.23674075121020458,
      "grad_norm": 6.24397087097168,
      "learning_rate": 3.884932196683573e-05,
      "loss": 0.2409,
      "step": 6700
    },
    {
      "epoch": 0.24027419525811808,
      "grad_norm": 5.227469444274902,
      "learning_rate": 3.866947232113953e-05,
      "loss": 0.2532,
      "step": 6800
    },
    {
      "epoch": 0.24380763930603158,
      "grad_norm": 4.758561134338379,
      "learning_rate": 3.848962267544333e-05,
      "loss": 0.2423,
      "step": 6900
    },
    {
      "epoch": 0.24734108335394508,
      "grad_norm": 11.382200241088867,
      "learning_rate": 3.830977302974713e-05,
      "loss": 0.2431,
      "step": 7000
    }
  ],
  "logging_steps": 100,
  "max_steps": 28301,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 10,
  "trial_name": null,
  "trial_params": null
}
